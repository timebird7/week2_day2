# # 20181218에 배운내용

#### 로또

```python
import random
import requests as req
from bs4 import BeautifulSoup as bs
# 1~45 까지의 숫자를 가진 numbers라는 배열을 만든다
# 반복문 1~45까지해서 하나씩 배열에 넣는 방법도 있습니다.
# python make long array / make number array
# python range to list
# 1
numbers = []
for i in range(45):
  numbers.append(i+1)

# 2
# lotto2 = list(range(1,46))
# print(lotto2)

# numbers에서 숫자 6개를 랜덤으로 뽑는다. (당연히 비복원 추출)
# 랜덤으로 뽑은 숫자들을 lotto 변수에 담고 출력한다

lotto = random.sample(numbers, 6)
lotto.sort()
print("이번주 로또 추천 번호는 {} 입니다.".format(lotto))

# 추가 : lotto 변수에 담겨있는 숫자들을 오름차순으로 정렬하기


url = 'https://m.dhlottery.co.kr/common.do?method=main'
response = req.get(url).text

soup = bs(response, 'html.parser')

lott = soup.select('.prizeresult')[0]
lot = lott.select('span')

ns = []
for number in lot:
  ns.append(int(number.text))  

ns.sort()
print(ns)  
count = 0
for num in ns:
    if num in lotto:
      count = count + 1
print(count)

# 지난 주 당첨 숫자 배열을 한번씩 순회하면서
# 내가 뽑아놓은 lotto배열에서 
# 몇개가 맞았는지 카운트 하기
```

네이버 코스피

```python
import requests as req
from bs4 import BeautifulSoup as bs

url = 'https://finance.naver.com/'
response = req.get(url).text

soup = bs(response, 'html.parser')

kospi = soup.select('.num')[0].text

print(kospi)
```

네이버 웹툰

```python
import requests
import time
from bs4 import BeautifulSoup as bs

today = time.strftime("%a").lower()
print(today)
# 네이버 웹툰을 가져올 수 있는 주소url을 파악한다.
# url 변수에 저장한다.
# 해당 주소로 요청을 보내 정보를 가져온다.
# 받은 정보를 bs를 이용해 검색하기 좋게 만든다
# 네이버 웹툰 페이지로 가서, 내가 원하는 정보가 어디에 있는지 파악한다.

url = 'https://comic.naver.com/webtoon/weekdayList.nhn?week=tue'
response = requests.get(url).text
soup = bs(response, 'html.parser')

toons = []
li = soup.select('.img_list li')
for item in li:
  toon = {
    'title' : item.select_one('dt a').text,
    'url' : item.select('dt a')[0]['href'],
    'img_url' : item.select('.thumb img')[0]['src']
  }
  toons.append(toon)
  
print(toons)


#   item.select_one('dt a')
#   item.select('dt a')[0]
#   위에 두줄은 같은 코드
```









다음 웹툰

```python
import requests
import time
from bs4 import BeautifulSoup as bs
import json

# 내가 원하는 정보를 얻을 수 있는 주소를 url이라고 하는 변수에 담는다.
# 해당 url에 요청을 보내 응답을 받아 저장한다.
# python으로 어떻게 json을 파싱(딕셔너리 형으로 전환) 구글링
# 내가 원하는 데이터를 꺼내서 조합한다.

url = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/wed'
response = requests.get(url).text
document = json.loads(response)
data = document['data']
toons = []
for toon in data:
  print(toon['title'])
  print(toon['pcThumbnailImage']['url'])
  print('http://webtoon.daum.net/webtoon/view/{}'.format(toon['nickname']))
```

